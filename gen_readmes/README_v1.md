# Project 2: Crowdfunding ETL

## Table of Contents
1. [Project Overview](#project-overview)  
2. [Directory Structure](#directory-structure)  
3. [Installation & Setup](#installation--setup)  
4. [ETL Process](#etl-process)  
5. [Schema Creation & (Optional) Data Import](#schema-creation--optional-data-import)  
6. [Regex Approach (Optional)](#regex-approach-optional)  
7. [ERD Overview](#erd-overview)  
8. [Usage Notes & Tips](#usage-notes--tips)  
9. [Credits & Citations](#credits--citations)

---

## Project Overview
This project focuses on **Extract, Transform, and Load (ETL)** processes to handle crowdfunding data. The main tasks include:

1. **Extracting** data from Excel files (`crowdfunding.xlsx` and `contacts.xlsx`).  
2. **Transforming** that data by cleaning columns, splitting attributes, and producing final CSV output (`campaign.csv`, `contacts.csv`, `category.csv`, `subcategory.csv`).  
3. **Loading** these CSVs into a Postgres database, demonstrated through a **SQL schema** script and **(optional) import** script.

While many ETL pipelines might use an ORM (e.g., SQLAlchemy), this project showcases how one can automate the generation of schema and import statements **directly** from a Python script.

---

## Directory Structure

```plaintext
CROWDFUNDING_ETL/
├── ETL
│   ├── Deliverables
│   │   ├── crowdfunding_db_schema.sql
│   │   └── ETL_FINAL.ipynb        <-- This is your main ETL script (a.k.a. "main_ETL.py")
│   └── Extras
│       ├── crowdfunding_db_import.sql   <-- Optional import script
│       └── schema_writer.py             <-- Optional script that auto-generates .sql files
├── Resources
│   ├── Input
│   │   ├── contacts.xlsx
│   │   └── crowdfunding.xlsx
│   └── Output
│       ├── campaign.csv
│       ├── category.csv
│       ├── contacts.csv
│       └── subcategory.csv
├── .gitignore
├── ERD.jpg
└── README.md
```

### Key Files (at a Glance)
- **ETL_FINAL.ipynb (main_ETL.py)**  
  - The main Python script that reads in Excel files, cleans/transforms the data, and exports final CSVs.  

- **schema_writer.py (Optional)**  
  - A convenience script that **auto-generates** SQL scripts (`crowdfunding_db_schema.sql` and `crowdfunding_db_import.sql`).  

- **crowdfunding_db_schema.sql**  
  - A Postgres schema script that creates tables for all final CSV outputs.  

- **crowdfunding_db_import.sql (Optional)**  
  - A Postgres script that bulk-imports the CSV data into the newly created tables.  

---

## Installation & Setup

1. **Clone/Download** this repository to your local machine.
2. Ensure you have **Python 3.x** installed, along with the **pandas** library:
   ```bash
   pip install pandas
   ```
3. (Optional) Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate     # Mac/Linux
   venv\Scriptsctivate        # Windows
   ```

---

## ETL Process

### 1. Extraction
- **Input**: `crowdfunding.xlsx` and `contacts.xlsx` in `Resources/Input/`.
- **ETL_FINAL.ipynb**:
  - Reads in the `.xlsx` files using pandas.
  - Performs initial cleaning (dropping columns, renaming, converting dtypes).

### 2. Transformation
- Splits out `category` and `subcategory` fields.
- Creates cleaned, structured CSV files:  
  - `campaign.csv`  
  - `contacts.csv`  
  - `category.csv`  
  - `subcategory.csv`
- Outputs to `Resources/Output/`.

### 3. Loading
- The actual load is demonstrated by the presence of `crowdfunding_db_schema.sql` and the optional `crowdfunding_db_import.sql`.  

---

## Schema Creation & (Optional) Data Import

### schema_writer.py (Optional)
- Reads the final CSV outputs and programmatically builds table creation statements (for `crowdfunding_db_schema.sql`) and CSV COPY statements (for `crowdfunding_db_import.sql`).  
- Helpful if your schema evolves or you have to regenerate scripts frequently.

### crowdfunding_db_schema.sql
- Contains `CREATE TABLE` statements, including data types matched to your CSV columns.

### crowdfunding_db_import.sql (Optional)
- Contains `COPY` statements that load each CSV file into the corresponding Postgres table.  
- Generated by `schema_writer.py` but **not** strictly required by the course assignment.

### Usage
- **In pgAdmin or psql**:
  ```sql
  \i crowdfunding_db_schema.sql
  -- Optionally
  \i crowdfunding_db_import.sql
  ```
- Verify with quick queries like:
  ```sql
  SELECT * FROM campaign;
  ```

---

## Regex Approach (Optional)
Another possible approach (demonstrated in `regex_sol.py`) relies on **regular expressions** for data parsing (especially for fields like names, emails, IDs). This can be beneficial if your data is unstructured or if you prefer a non-pandas string-parsing workflow. However, the **pandas-based approach** in `ETL_FINAL.ipynb` is more concise and meets the project’s requirements efficiently.

---

## ERD Overview

![ERD Diagram](./ERD.jpg)

- **campaign** → Connects to **contacts** via `contact_id`.  
- **campaign** → Connects to **category** and **subcategory** via `category_id` and `subcategory_id`.  

---

## Usage Notes & Tips

- **Modifying Paths**: If you relocate the CSVs or the `.sql` scripts, update references in `ETL_FINAL.ipynb` or `schema_writer.py`.
- **Manual vs. Automated**: You can manually write/modify `crowdfunding_db_schema.sql` if you need additional constraints like `PRIMARY KEY` or `FOREIGN KEY`.
- **Future Expandability**: The schema is sized for larger data sets. You can add constraints (PK/FK) as needed to ensure referential integrity.

---

## Credits & Citations

1. **Author**: _[Your Name]_  
2. **Starter Code & Data**: Provided by edX/2U.  
3. **OpenAI & ChatGPT**: For partial assistance in generating this README’s structure.  
4. **PostgreSQL Docs**: [postgresql.org/docs](https://www.postgresql.org/docs/)  
5. **pandas Docs**: [pandas.pydata.org/docs](https://pandas.pydata.org/docs)

---

**Thank you for exploring this Crowdfunding ETL project!**  
If you have suggestions or encounter issues, feel free to open an issue or submit a pull request.